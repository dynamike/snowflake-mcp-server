# Migration Guide: v0.2.0 ‚Üí v1.0.0

This guide helps you migrate from the original Snowflake MCP server (v0.2.0) to the new enterprise-grade version (v1.0.0) with async operations, connection pooling, daemon mode, and comprehensive monitoring.

## üìã Overview

The v1.0.0 release represents a complete architectural transformation:

**v0.2.0 (Legacy):**
- Singleton connection pattern
- Blocking synchronous operations
- stdio-only deployment
- Single-client focused
- Basic error handling

**v1.0.0 (Enterprise):**
- Async connection pooling
- True async/await operations
- HTTP/WebSocket + stdio support
- Multi-client architecture
- Advanced monitoring & security

## ‚ö° Quick Migration Checklist

- [ ] **Backup existing configuration** (`.env` files)
- [ ] **Update dependencies** (`uv pip install -e .`)
- [ ] **Review configuration changes** (see [Configuration Changes](#configuration-changes))
- [ ] **Choose deployment mode** (stdio, HTTP, daemon)
- [ ] **Test with your existing clients**
- [ ] **Configure monitoring** (optional but recommended)
- [ ] **Update integration scripts** (if any)

## üîÑ Migration Paths

### Path A: Drop-in Replacement (Recommended)

For most users, v1.0.0 is a drop-in replacement:

```bash
# 1. Stop existing server
pkill -f snowflake-mcp

# 2. Update to v1.0.0
git pull origin main
uv pip install -e .

# 3. Start new server (same command)
uv run snowflake-mcp-stdio
```

**Benefits:** Minimal changes required, immediate async performance boost.

### Path B: Daemon Mode Upgrade

For production deployments requiring high availability:

```bash
# 1. Install v1.0.0
uv pip install -e .

# 2. Configure daemon mode
cp ecosystem.config.js.example ecosystem.config.js
# Edit configuration for your environment

# 3. Start daemon
npm install -g pm2
pm2 start ecosystem.config.js

# 4. Update MCP client configuration to use HTTP/WebSocket
```

**Benefits:** Background operation, auto-restart, multiple clients, monitoring.

### Path C: Gradual Migration

For environments requiring zero downtime:

```bash
# 1. Deploy v1.0.0 alongside existing v0.2.0
# 2. Configure v1.0.0 on different port (e.g., 8001)
# 3. Test with subset of clients
# 4. Gradually migrate clients to new instance
# 5. Decommission v0.2.0 when all clients migrated
```

**Benefits:** Zero downtime, gradual rollout, easy rollback.

## üìù Configuration Changes

### Environment Variables

| Variable | v0.2.0 | v1.0.0 | Notes |
|----------|--------|--------|-------|
| `SNOWFLAKE_ACCOUNT` | ‚úÖ | ‚úÖ | No change |
| `SNOWFLAKE_USER` | ‚úÖ | ‚úÖ | No change |
| `SNOWFLAKE_PASSWORD` | ‚úÖ | ‚úÖ | No change |
| `SNOWFLAKE_WAREHOUSE` | ‚úÖ | ‚úÖ | No change |
| `SNOWFLAKE_DATABASE` | ‚úÖ | ‚úÖ | No change |
| `SNOWFLAKE_SCHEMA` | ‚úÖ | ‚úÖ | No change |
| `SNOWFLAKE_PRIVATE_KEY` | ‚úÖ | ‚úÖ | No change |
| `SNOWFLAKE_PRIVATE_KEY_PASSPHRASE` | ‚úÖ | ‚úÖ | No change |
| `SNOWFLAKE_AUTHENTICATOR` | ‚úÖ | ‚úÖ | No change |
| `SNOWFLAKE_CONN_REFRESH_HOURS` | ‚ùå | ‚úÖ | **NEW**: Connection refresh interval |
| `MCP_SERVER_HOST` | ‚ùå | ‚úÖ | **NEW**: HTTP server host |
| `MCP_SERVER_PORT` | ‚ùå | ‚úÖ | **NEW**: HTTP server port |
| `CONNECTION_POOL_MIN_SIZE` | ‚ùå | ‚úÖ | **NEW**: Minimum pool connections |
| `CONNECTION_POOL_MAX_SIZE` | ‚ùå | ‚úÖ | **NEW**: Maximum pool connections |
| `ENABLE_MONITORING` | ‚ùå | ‚úÖ | **NEW**: Enable Prometheus metrics |
| `LOG_LEVEL` | ‚ùå | ‚úÖ | **NEW**: Logging verbosity |

### New Configuration File: `.env`

Create or update your `.env` file:

```bash
# Core Snowflake connection (unchanged)
SNOWFLAKE_ACCOUNT=your_account
SNOWFLAKE_USER=your_user
SNOWFLAKE_PASSWORD=your_password
SNOWFLAKE_WAREHOUSE=your_warehouse
SNOWFLAKE_DATABASE=your_database
SNOWFLAKE_SCHEMA=your_schema

# NEW: Performance tuning
SNOWFLAKE_CONN_REFRESH_HOURS=8
CONNECTION_POOL_MIN_SIZE=3
CONNECTION_POOL_MAX_SIZE=10

# NEW: Server configuration
MCP_SERVER_HOST=0.0.0.0
MCP_SERVER_PORT=8000

# NEW: Monitoring and logging
ENABLE_MONITORING=true
LOG_LEVEL=INFO
```

## üöÄ Deployment Modes

### stdio Mode (Default - Backward Compatible)

**v0.2.0 command:**
```bash
python -m snowflake_mcp_server.main
```

**v1.0.0 equivalent:**
```bash
uv run snowflake-mcp-stdio
# or
python -m snowflake_mcp_server.main
```

**Client configuration:** No changes required for Claude Desktop.

### HTTP Mode (New)

Start HTTP server:
```bash
uv run snowflake-mcp --mode http
```

**Client configuration update** for Claude Desktop:
```json
{
  "mcpServers": {
    "snowflake": {
      "command": "curl",
      "args": [
        "-X", "POST",
        "http://localhost:8000/mcp",
        "-H", "Content-Type: application/json",
        "-d", "@-"
      ]
    }
  }
}
```

### Daemon Mode (Production)

Install PM2 and start daemon:
```bash
npm install -g pm2
pm2 start ecosystem.config.js
pm2 save
pm2 startup
```

**Client configuration** can use HTTP or WebSocket endpoints.

## üîß Client Integration Updates

### Claude Desktop

**v0.2.0 configuration:**
```json
{
  "mcpServers": {
    "snowflake": {
      "command": "uv",
      "args": ["run", "snowflake-mcp-stdio"],
      "env": {
        "SNOWFLAKE_ACCOUNT": "your_account"
      }
    }
  }
}
```

**v1.0.0 stdio (no change needed):**
```json
{
  "mcpServers": {
    "snowflake": {
      "command": "uv",
      "args": ["run", "snowflake-mcp-stdio"],
      "env": {
        "SNOWFLAKE_ACCOUNT": "your_account"
      }
    }
  }
}
```

**v1.0.0 HTTP mode:**
```json
{
  "mcpServers": {
    "snowflake": {
      "command": "curl",
      "args": [
        "-X", "POST", 
        "http://localhost:8000/mcp",
        "-H", "Content-Type: application/json",
        "-d", "@-"
      ]
    }
  }
}
```

### Custom Clients

If you have custom MCP clients, update them to handle:

1. **Async responses:** Operations may take longer but handle more concurrency
2. **Error handling:** More detailed error messages and recovery
3. **Rate limiting:** Built-in rate limiting for fair resource usage

## üìä Performance Expectations

### Performance Improvements

| Metric | v0.2.0 | v1.0.0 | Improvement |
|--------|--------|--------|-------------|
| Concurrent Clients | 1-2 | 50+ | 25x+ |
| Query Latency | Baseline | <100ms overhead | Better |
| Throughput | Baseline | 10x under load | 10x |
| Memory per Client | Baseline | 50% reduction | 2x better |
| Connection Recovery | Manual | <30s automatic | Automatic |

### Migration Performance Testing

Test your workload before full migration:

```bash
# Run integration tests
pytest tests/test_async_integration.py -v

# Run load tests
pytest tests/test_load_testing.py::test_low_concurrency_baseline -v

# Test your specific use case
python your_test_script.py
```

## üõ†Ô∏è Troubleshooting Migration Issues

### Issue: "ImportError: No module named 'asyncio_pool'"

**Solution:** Update dependencies
```bash
uv pip install -e .
```

### Issue: "Connection pool not initialized"

**Cause:** Async infrastructure not started
**Solution:** Ensure proper initialization:
```python
from snowflake_mcp_server.main import initialize_async_infrastructure
await initialize_async_infrastructure()
```

### Issue: "Port already in use" (HTTP mode)

**Solution:** Change port or stop conflicting process
```bash
# Change port
export MCP_SERVER_PORT=8001

# Or kill conflicting process
lsof -ti:8000 | xargs kill
```

### Issue: Higher memory usage initially

**Cause:** Connection pool initialization
**Solution:** Adjust pool size in configuration:
```bash
export CONNECTION_POOL_MIN_SIZE=2
export CONNECTION_POOL_MAX_SIZE=5
```

### Issue: "Permission denied" (daemon mode)

**Solution:** Set up proper permissions for PM2:
```bash
pm2 startup
# Follow the provided command
```

### Issue: Slower single queries

**Cause:** Async overhead for simple operations
**Expected:** <100ms overhead, but much better concurrent performance
**Mitigation:** Use connection pooling benefits for overall throughput

## üîç Monitoring Migration Success

### Health Checks

```bash
# Check stdio mode
echo '{"jsonrpc": "2.0", "id": 1, "method": "tools/list"}' | uv run snowflake-mcp-stdio

# Check HTTP mode
curl -X POST http://localhost:8000/health

# Check daemon mode
pm2 status snowflake-mcp
pm2 logs snowflake-mcp
```

### Performance Monitoring

Enable monitoring to track migration success:

```bash
# Enable Prometheus metrics
export ENABLE_MONITORING=true

# View metrics
curl http://localhost:8000/metrics

# Key metrics to watch:
# - mcp_requests_total
# - mcp_request_duration_seconds
# - pool_connections_active
# - pool_connections_total
```

### Log Analysis

Monitor logs for issues:

```bash
# stdio mode logs
uv run snowflake-mcp-stdio 2>&1 | tee migration.log

# Daemon mode logs  
pm2 logs snowflake-mcp

# Look for:
# - "Async infrastructure initialized" (success)
# - "Connection pool initialized" (success)  
# - "ERROR" or "FAILED" messages (issues)
```

## üìà Post-Migration Optimization

### 1. Tune Connection Pool

Monitor pool usage and adjust:

```bash
# Monitor pool metrics
curl http://localhost:8000/metrics | grep pool

# Adjust based on usage
export CONNECTION_POOL_MIN_SIZE=5
export CONNECTION_POOL_MAX_SIZE=20
```

### 2. Configure Rate Limiting

For high-traffic environments:

```bash
export ENABLE_RATE_LIMITING=true
export RATE_LIMIT_REQUESTS_PER_MINUTE=100
```

### 3. Set Up Monitoring Dashboard

Configure Grafana dashboard using provided configuration in `deploy/monitoring/`.

### 4. Configure Alerting

Set up alerts for:
- High error rates
- Connection pool exhaustion  
- Long query times
- System resource usage

## üîÑ Rollback Plan

If issues arise, quick rollback options:

### Rollback to v0.2.0

```bash
# 1. Stop v1.0.0
pm2 stop snowflake-mcp  # daemon mode
# or kill stdio process

# 2. Checkout v0.2.0
git checkout v0.2.0
uv pip install -e .

# 3. Start v0.2.0
python -m snowflake_mcp_server.main
```

### Temporary Workaround

Use stdio mode as fallback:
```bash
# Even in v1.0.0, stdio mode provides v0.2.0 compatibility
uv run snowflake-mcp-stdio
```

## üìû Support

### Getting Help

1. **Check logs** for specific error messages
2. **Review documentation** in `CLAUDE.md`
3. **Run diagnostics:**
   ```bash
   pytest tests/test_async_integration.py::test_async_performance_benchmarks -v -s
   ```
4. **Create issue** with:
   - Migration path used
   - Error logs
   - Configuration files (sanitized)
   - System information

### Common Questions

**Q: Do I need to change my client code?**
A: No, stdio mode is backward compatible. HTTP/WebSocket modes require client configuration updates.

**Q: Will this break my existing workflows?**
A: No, all MCP tools remain the same. Performance should improve.

**Q: Can I run both versions simultaneously?**
A: Yes, use different ports or stdio vs HTTP modes.

**Q: How do I know the migration succeeded?**
A: Check health endpoints, monitor metrics, verify client connectivity.

**Q: What if I have custom authentication?**
A: All existing authentication methods are supported unchanged.

## üéØ Migration Success Criteria

Your migration is successful when:

- [ ] **All clients connect** without errors
- [ ] **Query responses** are correct and timely  
- [ ] **Performance metrics** show improvement
- [ ] **Health checks** pass consistently
- [ ] **Monitoring** shows stable operation
- [ ] **No error spikes** in logs
- [ ] **Resource usage** is within expected ranges

## üìö Additional Resources

- **Architecture Documentation:** [CLAUDE.md](CLAUDE.md)
- **Operations Guide:** [OPERATIONS_RUNBOOK.md](OPERATIONS_RUNBOOK.md)
- **Deployment Examples:** [deploy/](deploy/)
- **Monitoring Setup:** [deploy/monitoring/](deploy/monitoring/)
- **Performance Tuning:** [SCALING_GUIDE.md](SCALING_GUIDE.md)

---

**Migration completed successfully? üéâ**

Welcome to the enterprise-grade Snowflake MCP server! You now have access to async operations, connection pooling, multi-client support, comprehensive monitoring, and production-ready deployment options.